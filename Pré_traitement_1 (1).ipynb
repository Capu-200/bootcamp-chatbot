{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **0Ô∏è‚É£. Installation** des biblioth√®ques"
      ],
      "metadata": {
        "id": "U_YGcZuBjZgi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "0. # Installer nltk (si n√©cessaire)\n",
        "!pip install nltk pandas\n",
        "\n",
        "1 # Importer les biblioth√®ques\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        " # T√©l√©charger les ressources nltk (une seule fois)\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MT1D7JVmm503",
        "outputId": "b8416d23-9ef5-4314-a033-0afd0e7dfa45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "2# üìÇ Demande √† l'utilisateur de t√©l√©verser son fichier\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "EqlV4CShoyCb",
        "outputId": "e3222c68-623d-4186-d77d-85bc6f3c0fb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8c8a4b30-2bfc-47c4-9e40-6c858bb5d887\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8c8a4b30-2bfc-47c4-9e40-6c858bb5d887\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving livres_final_update_final avec auteur.xlsx to livres_final_update_final avec auteur (1).xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1Ô∏è‚É£ **V√©rifier le fichier source (df.head())**\n",
        "üéØ **Objectif** : Regarder la structure du fichier et confirmer les colonnes existantes."
      ],
      "metadata": {
        "id": "lyYWVP89sbeX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Charger le fichier (remplace \"mon_fichier.csv\" par le vrai nom)\n",
        "df = pd.read_excel(\"livres_final_update_final avec auteur (1).xlsx\")\n",
        "\n",
        "# V√©rifier les premi√®res lignes\n",
        "print(\"üîç Aper√ßu des donn√©es :\")\n",
        "print(df.head())\n",
        "\n",
        "# V√©rifier les colonnes disponibles\n",
        "print(\"\\nüìå Colonnes disponibles :\")\n",
        "print(df.columns)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POpQbGAbpz6B",
        "outputId": "3f4b4e3f-53d4-4de8-ce03-a8ebc0ad3037"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Aper√ßu des donn√©es :\n",
            "                                           Titre             Auteur  \\\n",
            "0           Taupe & Mulot. Atteindre les sommets      Henri Meunier   \n",
            "1                   La guerre et la paix. Vol. 1       L√©on Tolsto√Ø   \n",
            "2                              L'√¢ge de la for√™t  Charline Collette   \n",
            "3  Des pas dans mon ciel bleu : CE1, s√©rie jaune  Nadine Brun-Cosme   \n",
            "4             10 bonnes raisons de te d√©tester !         Emma Green   \n",
            "\n",
            "               √âditeur                                        Description  \\\n",
            "0               H√©lium  - Aaaaahhhh... ! - Mulot ! Mulot ! √áa va, peti...   \n",
            "1            Gallimard  - Ah ! enlevez ces... enlevez donc ces... (Ell...   \n",
            "2         Joie de lire  - Alors le grand ch√™ne est plus vieux que toi ...   \n",
            "3               Hatier  - Alors voil√†, a conclu Papa en m'√©cartant tr√®...   \n",
            "4  Editions Addictives  - Arr√™te de te croire irr√©sistible, art. - Arr...   \n",
            "\n",
            "   Prix                                          Image URL  \\\n",
            "0  13.9  https://media.electre-ng.com/images/image-id/8...   \n",
            "1  10.5  https://media.electre-ng.com/images/image-id/3...   \n",
            "2  15.9  https://media.electre-ng.com/images/image-id/b...   \n",
            "3   4.2  https://media.electre-ng.com/images/image-id/4...   \n",
            "4  15.9  https://media.electre-ng.com/images/image-id/2...   \n",
            "\n",
            "                                                Lien  \\\n",
            "0  https://www.mollat.com/livres/2897100/henri-me...   \n",
            "1  https://www.mollat.com/livres/229752/leon-tols...   \n",
            "2  https://www.mollat.com/livres/2567474/charline...   \n",
            "3  https://www.mollat.com/livres/1520375/nadine-b...   \n",
            "4  https://www.mollat.com/livres/2408596/emma-gre...   \n",
            "\n",
            "                                     Cat√©gorie  \n",
            "0                                     jeunesse  \n",
            "1  litterature-romanesque-historique-et-autres  \n",
            "2                                     jeunesse  \n",
            "3                                     scolaire  \n",
            "4  litterature-romanesque-historique-et-autres  \n",
            "\n",
            "üìå Colonnes disponibles :\n",
            "Index(['Titre', 'Auteur', '√âditeur', 'Description', 'Prix', 'Image URL',\n",
            "       'Lien', 'Cat√©gorie'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2Ô∏è‚É£**Ajouter une colonne \"Publication\"**\n",
        " üéØ **Objectif** :\n",
        " Comme nous n'avons pas encore les ann√©es de publication, nous allons ajouter une colonne vide qui sera remplie plus tard avec l'API Google Books."
      ],
      "metadata": {
        "id": "sxwnObhds4mc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ajouter une colonne vide pour l'ann√©e de publication\n",
        "df[\"Publication\"] = None\n",
        "\n",
        "# V√©rifier que la colonne a bien √©t√© ajout√©e\n",
        "print(\"‚úÖ Colonne 'Publication' ajout√©e avec succ√®s !\")\n",
        "print(df.head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CVH1pxitCNo",
        "outputId": "6ab4e3e5-41d4-40e6-d62a-2ea7d6689054"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Colonne 'Publication' ajout√©e avec succ√®s !\n",
            "                                           Titre             Auteur  \\\n",
            "0           Taupe & Mulot. Atteindre les sommets      Henri Meunier   \n",
            "1                   La guerre et la paix. Vol. 1       L√©on Tolsto√Ø   \n",
            "2                              L'√¢ge de la for√™t  Charline Collette   \n",
            "3  Des pas dans mon ciel bleu : CE1, s√©rie jaune  Nadine Brun-Cosme   \n",
            "4             10 bonnes raisons de te d√©tester !         Emma Green   \n",
            "\n",
            "               √âditeur                                        Description  \\\n",
            "0               H√©lium  - Aaaaahhhh... ! - Mulot ! Mulot ! √áa va, peti...   \n",
            "1            Gallimard  - Ah ! enlevez ces... enlevez donc ces... (Ell...   \n",
            "2         Joie de lire  - Alors le grand ch√™ne est plus vieux que toi ...   \n",
            "3               Hatier  - Alors voil√†, a conclu Papa en m'√©cartant tr√®...   \n",
            "4  Editions Addictives  - Arr√™te de te croire irr√©sistible, art. - Arr...   \n",
            "\n",
            "   Prix                                          Image URL  \\\n",
            "0  13.9  https://media.electre-ng.com/images/image-id/8...   \n",
            "1  10.5  https://media.electre-ng.com/images/image-id/3...   \n",
            "2  15.9  https://media.electre-ng.com/images/image-id/b...   \n",
            "3   4.2  https://media.electre-ng.com/images/image-id/4...   \n",
            "4  15.9  https://media.electre-ng.com/images/image-id/2...   \n",
            "\n",
            "                                                Lien  \\\n",
            "0  https://www.mollat.com/livres/2897100/henri-me...   \n",
            "1  https://www.mollat.com/livres/229752/leon-tols...   \n",
            "2  https://www.mollat.com/livres/2567474/charline...   \n",
            "3  https://www.mollat.com/livres/1520375/nadine-b...   \n",
            "4  https://www.mollat.com/livres/2408596/emma-gre...   \n",
            "\n",
            "                                     Cat√©gorie Publication  \n",
            "0                                     jeunesse        None  \n",
            "1  litterature-romanesque-historique-et-autres        None  \n",
            "2                                     jeunesse        None  \n",
            "3                                     scolaire        None  \n",
            "4  litterature-romanesque-historique-et-autres        None  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3Ô∏è‚É£ **Utiliser l'API Google Books pour r√©cup√©rer les auteurs inconnus**\n",
        "üéØ Objectif : Rechercher les livres avec \"Auteur inconnu\" dans la colonne \"Auteur\" et utiliser Google Books API pour trouver les vrais auteurs."
      ],
      "metadata": {
        "id": "NqL02nu6taOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import time\n",
        "\n",
        "# Cl√© API Google Books (remplace \"YOUR_API_KEY\" par ta cl√©)\n",
        "API_KEY = \"YOUR_API_KEY\"\n",
        "\n",
        "# URL de l'API Google Books\n",
        "GOOGLE_BOOKS_API_URL = \"https://www.googleapis.com/books/v1/volumes\"\n",
        "\n",
        "def get_book_info(title):\n",
        "    \"\"\"Recherche un livre sur Google Books et retourne l'auteur trouv√©.\"\"\"\n",
        "    params = {\n",
        "        \"q\": f\"{title} livre\",\n",
        "        \"maxResults\": 1,\n",
        "        \"key\": API_KEY\n",
        "    }\n",
        "    response = requests.get(GOOGLE_BOOKS_API_URL, params=params)\n",
        "    data = response.json()\n",
        "\n",
        "    if \"items\" in data:\n",
        "        book_info = data[\"items\"][0][\"volumeInfo\"]\n",
        "        auteur = \", \".join(book_info.get(\"authors\", [\"Auteur inconnu\"]))\n",
        "        return auteur\n",
        "    return \"Auteur inconnu\"\n",
        "\n",
        "    # D√©but du chronom√®tre\n",
        "start_time = time.time()\n",
        "\n",
        "# S√©lectionner uniquement les lignes o√π l'auteur est \"Auteur inconnu\"\n",
        "livres_sans_auteur = df[df[\"Auteur\"].str.lower() == \"auteur inconnu\"]\n",
        "\n",
        "# Barre de progression\n",
        "for index, row in tqdm(livres_sans_auteur.iterrows(), total=len(livres_sans_auteur), desc=\"üîÑ Recherche des auteurs via API\"):\n",
        "    df.at[index, \"Auteur\"] = get_book_info(row[\"Titre\"])\n",
        "\n",
        "# Calcul du temps d'ex√©cution\n",
        "elapsed_time = time.time() - start_time\n",
        "\n",
        "# V√©rifier les r√©sultats apr√®s mise √† jour\n",
        "auteurs_trouves = df[df[\"Auteur\"].str.lower() != \"auteur inconnu\"]\n",
        "\n",
        "print(\"\\n‚úÖ Mise √† jour des auteurs termin√©e.\")\n",
        "print(f\"‚è≥ Temps total : {elapsed_time:.2f} secondes\")\n",
        "print(f\"üìå Nombre d'auteurs trouv√©s : {len(auteurs_trouves)}\")\n",
        "print(f\"üìå Nombre restant 'Auteur inconnu' : {len(df[df['Auteur'].str.lower() == 'auteur inconnu'])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itWlrupktd4B",
        "outputId": "8851a6ee-6cdf-4004-a2bf-584d0186e94c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üîÑ Recherche des auteurs via API: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7983/7983 [02:31<00:00, 52.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Mise √† jour des auteurs termin√©e.\n",
            "‚è≥ Temps total : 151.22 secondes\n",
            "üìå Nombre d'auteurs trouv√©s : 63230\n",
            "üìå Nombre restant 'Auteur inconnu' : 7983\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4Ô∏è‚É£ **Utiliser l'API Google Books pour r√©cup√©rer les descriptions**\n",
        "üéØ **Objectif** : Remplacer les descriptions incorrectes (\"pas de description disponible\", \"exp√©di√© par\", etc.) par des r√©sum√©s corrects √† l‚Äôaide de Google Books API."
      ],
      "metadata": {
        "id": "AZDsoGEQv5WN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Renommer la colonne \"Description\" en \"R√©sum√©\"\n",
        "df.rename(columns={\"Description\": \"R√©sum√©\"}, inplace=True)\n",
        "\n",
        "# V√©rifier le changement\n",
        "print(\"‚úÖ La colonne 'Description' a √©t√© renomm√©e en 'R√©sum√©'\")\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnRfABKdwuma",
        "outputId": "616f2420-05ad-4755-a89d-62fa8093709e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ La colonne 'Description' a √©t√© renomm√©e en 'R√©sum√©'\n",
            "                                           Titre             Auteur  \\\n",
            "0           Taupe & Mulot. Atteindre les sommets      Henri Meunier   \n",
            "1                   La guerre et la paix. Vol. 1       L√©on Tolsto√Ø   \n",
            "2                              L'√¢ge de la for√™t  Charline Collette   \n",
            "3  Des pas dans mon ciel bleu : CE1, s√©rie jaune  Nadine Brun-Cosme   \n",
            "4             10 bonnes raisons de te d√©tester !         Emma Green   \n",
            "\n",
            "               √âditeur                                             R√©sum√©  \\\n",
            "0               H√©lium  - Aaaaahhhh... ! - Mulot ! Mulot ! √áa va, peti...   \n",
            "1            Gallimard  - Ah ! enlevez ces... enlevez donc ces... (Ell...   \n",
            "2         Joie de lire  - Alors le grand ch√™ne est plus vieux que toi ...   \n",
            "3               Hatier  - Alors voil√†, a conclu Papa en m'√©cartant tr√®...   \n",
            "4  Editions Addictives  - Arr√™te de te croire irr√©sistible, art. - Arr...   \n",
            "\n",
            "   Prix                                          Image URL  \\\n",
            "0  13.9  https://media.electre-ng.com/images/image-id/8...   \n",
            "1  10.5  https://media.electre-ng.com/images/image-id/3...   \n",
            "2  15.9  https://media.electre-ng.com/images/image-id/b...   \n",
            "3   4.2  https://media.electre-ng.com/images/image-id/4...   \n",
            "4  15.9  https://media.electre-ng.com/images/image-id/2...   \n",
            "\n",
            "                                                Lien  \\\n",
            "0  https://www.mollat.com/livres/2897100/henri-me...   \n",
            "1  https://www.mollat.com/livres/229752/leon-tols...   \n",
            "2  https://www.mollat.com/livres/2567474/charline...   \n",
            "3  https://www.mollat.com/livres/1520375/nadine-b...   \n",
            "4  https://www.mollat.com/livres/2408596/emma-gre...   \n",
            "\n",
            "                                     Cat√©gorie Publication  \n",
            "0                                     jeunesse        None  \n",
            "1  litterature-romanesque-historique-et-autres        None  \n",
            "2                                     jeunesse        None  \n",
            "3                                     scolaire        None  \n",
            "4  litterature-romanesque-historique-et-autres        None  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_book_summary(title, isbn=None):\n",
        "    \"\"\"Recherche un livre sur Google Books et retourne l'auteur et le r√©sum√©.\"\"\"\n",
        "\n",
        "    if isbn:\n",
        "        params = {\"q\": f\"isbn:{isbn}\", \"maxResults\": 1, \"key\": API_KEY}\n",
        "    else:\n",
        "        params = {\"q\": f\"{title} livre r√©sum√©\", \"maxResults\": 1, \"key\": API_KEY}\n",
        "\n",
        "    response = requests.get(GOOGLE_BOOKS_API_URL, params=params)\n",
        "    data = response.json()\n",
        "\n",
        "    if \"items\" in data:\n",
        "        book_info = data[\"items\"][0][\"volumeInfo\"]\n",
        "        auteur = \", \".join(book_info.get(\"authors\", [\"Auteur inconnu\"]))\n",
        "        resume = book_info.get(\"description\", \"R√©sum√© non disponible\")\n",
        "        return auteur, resume\n",
        "\n",
        "    return \"Auteur inconnu\", \"R√©sum√© non disponible\"\n",
        "# D√©but du chronom√®tre\n",
        "start_time = time.time()\n",
        "\n",
        "# Liste des valeurs √† remplacer dans la colonne \"R√©sum√©\"\n",
        "descriptions_vides = [\"description non disponible\", \"exp√©di√© par\", \"pas de description disponible\"]\n",
        "\n",
        "# S√©lectionner uniquement les lignes o√π le r√©sum√© est incorrect\n",
        "livres_sans_resume = df[df[\"R√©sum√©\"].str.lower().isin(descriptions_vides)]\n",
        "\n",
        "# Barre de progression\n",
        "for index, row in tqdm(livres_sans_resume.iterrows(), total=len(livres_sans_resume), desc=\"üìñ Recherche des r√©sum√©s via API\"):\n",
        "    isbn = row[\"ISBN\"] if \"ISBN\" in df.columns and pd.notna(row[\"ISBN\"]) else None\n",
        "    _, resume = get_book_summary(row[\"Titre\"], isbn)\n",
        "    df.at[index, \"R√©sum√©\"] = resume\n",
        "\n",
        "# Calcul du temps d'ex√©cution\n",
        "elapsed_time = time.time() - start_time\n",
        "\n",
        "# V√©rifier les r√©sultats apr√®s mise √† jour\n",
        "resumes_restants = df[df[\"R√©sum√©\"].str.lower().isin(descriptions_vides)]\n",
        "\n",
        "print(\"\\n‚úÖ Mise √† jour des r√©sum√©s termin√©e.\")\n",
        "print(f\"‚è≥ Temps total : {elapsed_time:.2f} secondes\")\n",
        "print(f\"üìå Nombre restant 'R√©sum√© non disponible' apr√®s mise √† jour : {len(resumes_restants)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "athoqdpUXdWl",
        "outputId": "28dce934-643e-496d-c028-12a7c5fad439"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üìñ Recherche des r√©sum√©s via API: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1771/1771 [00:30<00:00, 58.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Mise √† jour des r√©sum√©s termin√©e.\n",
            "‚è≥ Temps total : 30.85 secondes\n",
            "üìå Nombre restant 'R√©sum√© non disponible' apr√®s mise √† jour : 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5Ô∏è‚É£**Utiliser l'API Google Books pour r√©cup√©rer les dates de publication**\n",
        "üéØ **Objectif** : Remplacer les valeurs None dans la colonne \"Publication\" par la vraie ann√©e de publication gr√¢ce √† l‚ÄôAPI Google Books."
      ],
      "metadata": {
        "id": "9oHnQ6gvxZQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_book_details(title, isbn=None):\n",
        "    \"\"\"Recherche un livre sur Google Books et retourne l'auteur, le r√©sum√© et la date de publication.\"\"\"\n",
        "\n",
        "    if isbn:\n",
        "        params = {\"q\": f\"isbn:{isbn}\", \"maxResults\": 1, \"key\": API_KEY}\n",
        "    else:\n",
        "        params = {\"q\": f\"{title} livre\", \"maxResults\": 1, \"key\": API_KEY}\n",
        "\n",
        "    response = requests.get(GOOGLE_BOOKS_API_URL, params=params)\n",
        "    data = response.json()\n",
        "\n",
        "    if \"items\" in data:\n",
        "        book_info = data[\"items\"][0][\"volumeInfo\"]\n",
        "        auteur = \", \".join(book_info.get(\"authors\", [\"Auteur inconnu\"]))\n",
        "        resume = book_info.get(\"description\", \"R√©sum√© non disponible\")\n",
        "        date_publication = book_info.get(\"publishedDate\", \"Date inconnue\")\n",
        "        return auteur, resume, date_publication\n",
        "\n",
        "    return \"Auteur inconnu\", \"R√©sum√© non disponible\", \"Date inconnue\"\n",
        "\n",
        "# D√©but du chronom√®tre\n",
        "start_time = time.time()\n",
        "\n",
        "# S√©lectionner uniquement les lignes o√π la date de publication est \"None\" ou \"Date inconnue\"\n",
        "livres_sans_date = df[df[\"Publication\"].isna() | (df[\"Publication\"] == \"Date inconnue\")]\n",
        "\n",
        "# Barre de progression\n",
        "for index, row in tqdm(livres_sans_date.iterrows(), total=len(livres_sans_date), desc=\"üìÖ Recherche des dates de publication via API\"):\n",
        "    isbn = row[\"ISBN\"] if \"ISBN\" in df.columns and pd.notna(row[\"ISBN\"]) else None\n",
        "    _, _, date_publication = get_book_details(row[\"Titre\"], isbn)\n",
        "    df.at[index, \"Publication\"] = date_publication\n",
        "\n",
        "# Calcul du temps d'ex√©cution\n",
        "elapsed_time = time.time() - start_time\n",
        "\n",
        "# V√©rifier les r√©sultats apr√®s mise √† jour\n",
        "dates_restantes = df[df[\"Publication\"].isna() | (df[\"Publication\"] == \"Date inconnue\")]\n",
        "\n",
        "print(\"\\n‚úÖ Mise √† jour des dates termin√©e.\")\n",
        "print(f\"‚è≥ Temps total : {elapsed_time:.2f} secondes\")\n",
        "print(f\"üìå Nombre restant 'Date inconnue' apr√®s mise √† jour : {len(dates_restantes)}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkAdlhhyxg8S",
        "outputId": "2ddce7c0-5f30-4580-905c-f8ab1b156eea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üìÖ Recherche des dates de publication via API: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 71213/71213 [22:04<00:00, 53.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Mise √† jour des dates termin√©e.\n",
            "‚è≥ Temps total : 1324.48 secondes\n",
            "üìå Nombre restant 'Date inconnue' apr√®s mise √† jour : 71213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# V√©rifier les premiers livres avec \"Date inconnue\"\n",
        "print(\"\\nüìå Exemples de livres sans date trouv√©e :\")\n",
        "print(df[df[\"Publication\"] == \"Date inconnue\"].head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqwTqAlGf2QH",
        "outputId": "0a52e9f5-cab2-4056-a132-4f417f0181d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìå Exemples de livres sans date trouv√©e :\n",
            "                                            Titre             Auteur  \\\n",
            "0            Taupe & Mulot. Atteindre les sommets      Henri Meunier   \n",
            "1                    La guerre et la paix. Vol. 1       L√©on Tolsto√Ø   \n",
            "2                               L'√¢ge de la for√™t  Charline Collette   \n",
            "3   Des pas dans mon ciel bleu : CE1, s√©rie jaune  Nadine Brun-Cosme   \n",
            "4              10 bonnes raisons de te d√©tester !         Emma Green   \n",
            "5                              La fl√ªte enchant√©e       Pierre Coran   \n",
            "6                                     Le bonhomme  Stephen Vuillemin   \n",
            "7                                       Oui & non      Elisha Cooper   \n",
            "8               Comment on construit une maison ?        C√©sar Canet   \n",
            "9  Vie et mort de l'homme qui tua John F. Kennedy  Anne-James Chaton   \n",
            "\n",
            "                  √âditeur                                             R√©sum√©  \\\n",
            "0                  H√©lium  - Aaaaahhhh... ! - Mulot ! Mulot ! √áa va, peti...   \n",
            "1               Gallimard  - Ah ! enlevez ces... enlevez donc ces... (Ell...   \n",
            "2            Joie de lire  - Alors le grand ch√™ne est plus vieux que toi ...   \n",
            "3                  Hatier  - Alors voil√†, a conclu Papa en m'√©cartant tr√®...   \n",
            "4     Editions Addictives  - Arr√™te de te croire irr√©sistible, art. - Arr...   \n",
            "5  P√®re Castor-Flammarion  - Bienvenue, Tamino ! dit la belle Pamina. Sai...   \n",
            "6   Albin Michel-Jeunesse  - Bonhomme, nous voulons nous d√©guiser en dino...   \n",
            "7            Le Gen√©vrier  - Bonjour, bonjour ! C'est l'heure de se lever...   \n",
            "8    Poids Plume √©ditions  - C'est vrai √ßa ! Comment on construit une mai...   \n",
            "9                     POL  - √áa venait d'o√π ? - Ils l'ont tu√©. - Vous ave...   \n",
            "\n",
            "   Prix                                          Image URL  \\\n",
            "0  13.9  https://media.electre-ng.com/images/image-id/8...   \n",
            "1  10.5  https://media.electre-ng.com/images/image-id/3...   \n",
            "2  15.9  https://media.electre-ng.com/images/image-id/b...   \n",
            "3   4.2  https://media.electre-ng.com/images/image-id/4...   \n",
            "4  15.9  https://media.electre-ng.com/images/image-id/2...   \n",
            "5  13.5  https://media.electre-ng.com/images/image-id/f...   \n",
            "6    18  https://media.electre-ng.com/images/image-id/8...   \n",
            "7    13  https://media.electre-ng.com/images/image-id/1...   \n",
            "8  14.5  https://media.electre-ng.com/images/image-id/9...   \n",
            "9  18.9  https://media.electre-ng.com/images/image-id/e...   \n",
            "\n",
            "                                                Lien  \\\n",
            "0  https://www.mollat.com/livres/2897100/henri-me...   \n",
            "1  https://www.mollat.com/livres/229752/leon-tols...   \n",
            "2  https://www.mollat.com/livres/2567474/charline...   \n",
            "3  https://www.mollat.com/livres/1520375/nadine-b...   \n",
            "4  https://www.mollat.com/livres/2408596/emma-gre...   \n",
            "5  https://www.mollat.com/livres/995822/pierre-co...   \n",
            "6  https://www.mollat.com/livres/3139513/stephen-...   \n",
            "7  https://www.mollat.com/livres/2493370/elisha-c...   \n",
            "8  https://www.mollat.com/livres/2945155/cesar-ca...   \n",
            "9  https://www.mollat.com/livres/2406311/anne-jam...   \n",
            "\n",
            "                                     Cat√©gorie    Publication  \n",
            "0                                     jeunesse  Date inconnue  \n",
            "1  litterature-romanesque-historique-et-autres  Date inconnue  \n",
            "2                                     jeunesse  Date inconnue  \n",
            "3                                     scolaire  Date inconnue  \n",
            "4  litterature-romanesque-historique-et-autres  Date inconnue  \n",
            "5                                     jeunesse  Date inconnue  \n",
            "6                                     jeunesse  Date inconnue  \n",
            "7                                     jeunesse  Date inconnue  \n",
            "8                                     jeunesse  Date inconnue  \n",
            "9                     biographies-beaux-livres  Date inconnue  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def get_book_year(title, isbn=None):\n",
        "    \"\"\"Recherche un livre sur Google Books et retourne l'ann√©e de publication.\"\"\"\n",
        "\n",
        "    if isbn:\n",
        "        params = {\"q\": f\"isbn:{isbn}\", \"maxResults\": 1, \"key\": API_KEY}\n",
        "    else:\n",
        "        params = {\"q\": f\"{title} livre\", \"maxResults\": 1, \"key\": API_KEY}\n",
        "\n",
        "    response = requests.get(GOOGLE_BOOKS_API_URL, params=params)\n",
        "    data = response.json()\n",
        "\n",
        "    if \"items\" in data:\n",
        "        book_info = data[\"items\"][0][\"volumeInfo\"]\n",
        "        date_publication = book_info.get(\"publishedDate\", \"Date inconnue\")\n",
        "\n",
        "        # Extraire uniquement l'ann√©e si un format plus long est trouv√©\n",
        "        match = re.search(r\"\\d{4}\", date_publication)  # Recherche une ann√©e (4 chiffres)\n",
        "        if match:\n",
        "            return match.group(0)  # Retourne uniquement l'ann√©e\n",
        "\n",
        "    return \"Date inconnue\"\n",
        "\n",
        "# D√©but du chronom√®tre\n",
        "start_time = time.time()\n",
        "\n",
        "# S√©lectionner uniquement les lignes o√π la date est \"Date inconnue\" ou \"non\"\n",
        "livres_sans_date = df[df[\"Publication\"].isna() | (df[\"Publication\"].str.lower() == \"non\") | (df[\"Publication\"] == \"Date inconnue\")]\n",
        "\n",
        "# Barre de progression\n",
        "for index, row in tqdm(livres_sans_date.iterrows(), total=len(livres_sans_date), desc=\"üìÖ Recherche des ann√©es de publication via API\"):\n",
        "    isbn = row[\"ISBN\"] if \"ISBN\" in df.columns and pd.notna(row[\"ISBN\"]) else None\n",
        "    year = get_book_year(row[\"Titre\"], isbn)\n",
        "    df.at[index, \"Publication\"] = year\n",
        "\n",
        "# Calcul du temps d'ex√©cution\n",
        "elapsed_time = time.time() - start_time\n",
        "\n",
        "# V√©rifier les r√©sultats apr√®s mise √† jour\n",
        "dates_restantes = df[df[\"Publication\"] == \"Date inconnue\"]\n",
        "\n",
        "print(\"\\n‚úÖ Mise √† jour des ann√©es termin√©e.\")\n",
        "print(f\"‚è≥ Temps total : {elapsed_time:.2f} secondes\")\n",
        "print(f\"üìå Nombre restant 'Date inconnue' apr√®s mise √† jour : {len(dates_restantes)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ipJiJIofNtz",
        "outputId": "913c5ad1-8781-4f86-eb1d-e96df4650ca1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üìÖ Recherche des ann√©es de publication via API: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 71213/71213 [22:13<00:00, 53.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Mise √† jour des ann√©es termin√©e.\n",
            "‚è≥ Temps total : 1333.57 secondes\n",
            "üìå Nombre restant 'Date inconnue' apr√®s mise √† jour : 71213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Supprimer la colonne \"Publication\"\n",
        "df.drop(columns=[\"Publication\"], inplace=True)\n",
        "\n",
        "# V√©rifier que la colonne a bien √©t√© supprim√©e\n",
        "print(\"‚úÖ Colonne 'Publication' supprim√©e avec succ√®s !\")\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROL8sImZucIE",
        "outputId": "0ad38cb0-d424-4c56-968b-aa40c2ace008"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Colonne 'Publication' supprim√©e avec succ√®s !\n",
            "                                           Titre             Auteur  \\\n",
            "0           Taupe & Mulot. Atteindre les sommets      Henri Meunier   \n",
            "1                   La guerre et la paix. Vol. 1       L√©on Tolsto√Ø   \n",
            "2                              L'√¢ge de la for√™t  Charline Collette   \n",
            "3  Des pas dans mon ciel bleu : CE1, s√©rie jaune  Nadine Brun-Cosme   \n",
            "4             10 bonnes raisons de te d√©tester !         Emma Green   \n",
            "\n",
            "               √âditeur                                             R√©sum√©  \\\n",
            "0               H√©lium  - Aaaaahhhh... ! - Mulot ! Mulot ! √áa va, peti...   \n",
            "1            Gallimard  - Ah ! enlevez ces... enlevez donc ces... (Ell...   \n",
            "2         Joie de lire  - Alors le grand ch√™ne est plus vieux que toi ...   \n",
            "3               Hatier  - Alors voil√†, a conclu Papa en m'√©cartant tr√®...   \n",
            "4  Editions Addictives  - Arr√™te de te croire irr√©sistible, art. - Arr...   \n",
            "\n",
            "   Prix                                          Image URL  \\\n",
            "0  13.9  https://media.electre-ng.com/images/image-id/8...   \n",
            "1  10.5  https://media.electre-ng.com/images/image-id/3...   \n",
            "2  15.9  https://media.electre-ng.com/images/image-id/b...   \n",
            "3   4.2  https://media.electre-ng.com/images/image-id/4...   \n",
            "4  15.9  https://media.electre-ng.com/images/image-id/2...   \n",
            "\n",
            "                                                Lien  \\\n",
            "0  https://www.mollat.com/livres/2897100/henri-me...   \n",
            "1  https://www.mollat.com/livres/229752/leon-tols...   \n",
            "2  https://www.mollat.com/livres/2567474/charline...   \n",
            "3  https://www.mollat.com/livres/1520375/nadine-b...   \n",
            "4  https://www.mollat.com/livres/2408596/emma-gre...   \n",
            "\n",
            "                                     Cat√©gorie  \n",
            "0                                     jeunesse  \n",
            "1  litterature-romanesque-historique-et-autres  \n",
            "2                                     jeunesse  \n",
            "3                                     scolaire  \n",
            "4  litterature-romanesque-historique-et-autres  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **üìå Plan des √©tapes pour le NLP Processing**\n",
        "1Ô∏è‚É£ **Normaliser le texte** : suppression des accents, mise en minuscules\n",
        "\n",
        "2Ô∏è‚É£ **Tokenisation** : d√©couper les textes en mots\n",
        "\n",
        "3Ô∏è‚É£ **Suppression des stopwords** : mots non significatifs comme \"le\", \"de\", \"et\"\n",
        "\n",
        "4Ô∏è‚É£ **Lemmatisation** : r√©duction des mots √† leur forme de base : \"manger\" ‚Üí \"mang√©\"\n",
        "\n",
        "5Ô∏è‚É£ **Vectorisation** TF-IDF\n",
        "\n",
        "6Ô∏è‚É£ **Export** du fichier final pour l‚Äôentra√Ænement IA."
      ],
      "metadata": {
        "id": "96ej3kGcs1Ol"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **üìå 1 : Mise en minuscule et suppression des accents**\n",
        "Convertir tout le texte en minuscules et remplacer les lettres accentu√©es sans les supprimer."
      ],
      "metadata": {
        "id": "6zq4UyivwR9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import unicodedata\n",
        "\n",
        "def normalize_text(text):\n",
        "    \"\"\"Met en minuscule et enl√®ve les accents du texte.\"\"\"\n",
        "    text = str(text).lower()  # Mise en minuscule\n",
        "    text = unicodedata.normalize(\"NFD\", text).encode(\"ascii\", \"ignore\").decode(\"utf-8\")  # Suppression des accents\n",
        "    return text\n",
        "\n",
        "# Appliquer le nettoyage sur les titres et r√©sum√©s\n",
        "df[\"Titre_clean\"] = df[\"Titre\"].apply(normalize_text)\n",
        "df[\"R√©sum√©_clean\"] = df[\"R√©sum√©\"].apply(normalize_text)\n",
        "\n",
        "# V√©rifier le r√©sultat\n",
        "print(\"‚úÖ Exemple avant/apr√®s la normalisation :\\n\")\n",
        "print(\"Avant :\", df[\"Titre\"].iloc[0])\n",
        "print(\"Apr√®s :\", df[\"Titre_clean\"].iloc[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klZT4VaXtn2H",
        "outputId": "d1d250ab-a03c-4fd3-e07d-de236b1415f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Exemple avant/apr√®s la normalisation :\n",
            "\n",
            "Avant : Taupe & Mulot. Atteindre les sommets\n",
            "Apr√®s : taupe & mulot. atteindre les sommets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìå **2 : Suppression des symboles mais conservation des nombres**\n",
        "‚úî Supprimer la ponctuation et les symboles.\n",
        "‚úî Conserver les nombres (dates, r√©f√©rences utiles)."
      ],
      "metadata": {
        "id": "l0wU58glw5gz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def remove_punctuation_keep_numbers(text):\n",
        "    \"\"\"Supprime la ponctuation et les symboles sp√©ciaux, mais garde les nombres.\"\"\"\n",
        "    text = re.sub(r\"[^\\w\\s\\d]\", \"\", text)  # Supprime la ponctuation mais garde les nombres\n",
        "    return text\n",
        "\n",
        "# Appliquer le nettoyage sur les colonnes\n",
        "df[\"Titre_clean\"] = df[\"Titre_clean\"].apply(remove_punctuation_keep_numbers)\n",
        "df[\"R√©sum√©_clean\"] = df[\"R√©sum√©_clean\"].apply(remove_punctuation_keep_numbers)\n",
        "\n",
        "# V√©rifier le r√©sultat\n",
        "print(\"‚úÖ Exemple avant/apr√®s suppression des symboles (mais conservation des nombres) :\\n\")\n",
        "print(\"Avant :\", df[\"Titre\"].iloc[0])\n",
        "print(\"Apr√®s :\", df[\"Titre_clean\"].iloc[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cdfzm8pKw_7Y",
        "outputId": "5b373863-5fb4-48b0-d79b-c6de800dcd27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Exemple avant/apr√®s suppression des symboles (mais conservation des nombres) :\n",
            "\n",
            "Avant : Taupe & Mulot. Atteindre les sommets\n",
            "Apr√®s : taupe  mulot atteindre les sommets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìå**3 : D√©coupage du texte en mots (Tokenisation)**\n",
        "Transformer le texte en une liste de mots (tokens) pour l‚Äôanalyse NLP.\n",
        "\n",
        "‚úî Facilite l‚Äôanalyse de chaque mot ind√©pendamment.\n",
        "\n",
        "‚úî Pr√©pare les donn√©es pour des mod√®les d‚ÄôIA (TF-IDF)."
      ],
      "metadata": {
        "id": "ywO5Z1ZixR1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download fr_core_news_sm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2YidNaHyW7M",
        "outputId": "3c11fb1f-69d3-4183-cbe5-d4a30c3f8199"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.12.14)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting fr-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.7.0/fr_core_news_sm-3.7.0-py3-none-any.whl (16.3 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from fr-core-news-sm==3.7.0) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.2.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2024.12.14)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.1.2)\n",
            "Installing collected packages: fr-core-news-sm\n",
            "Successfully installed fr-core-news-sm-3.7.0\n",
            "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_core_news_sm')\n",
            "\u001b[38;5;3m‚ö† Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Charger le mod√®le fran√ßais\n",
        "nlp = spacy.load(\"fr_core_news_sm\")\n",
        "\n",
        "def tokenize_text(text):\n",
        "    \"\"\"Tokenise un texte avec spacy\"\"\"\n",
        "    doc = nlp(text)\n",
        "    return [token.text for token in doc]\n",
        "\n",
        "# Appliquer la tokenisation avec une barre de progression\n",
        "tqdm.pandas(desc=\"üîÑ Tokenisation des r√©sum√©s\")\n",
        "df[\"tokens\"] = df[\"R√©sum√©_clean\"].progress_apply(tokenize_text)\n",
        "\n",
        "# V√©rifier les r√©sultats\n",
        "print(\"‚úÖ Exemple avant/apr√®s la tokenisation :\\n\")\n",
        "print(\"Avant :\", df[\"R√©sum√©_clean\"].iloc[0])\n",
        "print(\"Apr√®s :\", df[\"tokens\"].iloc[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMyM1kLsy4fR",
        "outputId": "820728ea-0353-401d-e099-b0165aaabc4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üîÑ Tokenisation des r√©sum√©s: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 71213/71213 [31:48<00:00, 37.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Exemple avant/apr√®s la tokenisation :\n",
            "\n",
            "Avant :  aaaaahhhh   mulot  mulot  ca va petit imprudent  combien de fois taije dit de toujours regarder ou tu poses le pied comme je le fais moimeme   aie aie aie  cesse donc de plaisanter taupe je crois bien que je me suis casse la patte taupe et mulot saiment plus que tout malgre leurs differences ils se voient tous les jours sentraident et partagent au gre des saisons escalade dans les arbres circuit de course dans le potager et bien dautres aventures  taupe ny voit vraiment pas grandchose mais son imagination et sa creativite sont sans limites il est un peu ronchon mais assez philosophe la personne en qui il a le plus confiance cest son meilleur ami mulot  ils sont inseparables taupe raffole du chocolat et de la tarte aux lombrics mulot est joyeux et enthousiaste applique en tout parfois un peu inquiet aussi il a toujours le bienetre de taupe a coeur et deploie des tresors dimagination pour ne jamais froisser son meilleur ami il vit tout pres de chez lui et pas un jour ne se passe sans quil lui rende visite avec une nouvelle occupation a partager\n",
            "Apr√®s : [' ', 'aaaaahhhh', '  ', 'mulot', ' ', 'mulot', ' ', 'ca', 'va', 'petit', 'imprudent', ' ', 'combien', 'de', 'fois', 'taije', 'dit', 'de', 'toujours', 'regarder', 'ou', 'tu', 'poses', 'le', 'pied', 'comme', 'je', 'le', 'fais', 'moimeme', '  ', 'aie', 'aie', 'aie', ' ', 'cesse', 'donc', 'de', 'plaisanter', 'taupe', 'je', 'crois', 'bien', 'que', 'je', 'me', 'suis', 'casse', 'la', 'patte', 'taupe', 'et', 'mulot', 'saiment', 'plus', 'que', 'tout', 'malgre', 'leurs', 'differences', 'ils', 'se', 'voient', 'tous', 'les', 'jours', 'sentraident', 'et', 'partagent', 'au', 'gre', 'des', 'saisons', 'escalade', 'dans', 'les', 'arbres', 'circuit', 'de', 'course', 'dans', 'le', 'potager', 'et', 'bien', 'dautres', 'aventures', ' ', 'taupe', 'ny', 'voit', 'vraiment', 'pas', 'grandchose', 'mais', 'son', 'imagination', 'et', 'sa', 'creativite', 'sont', 'sans', 'limites', 'il', 'est', 'un', 'peu', 'ronchon', 'mais', 'assez', 'philosophe', 'la', 'personne', 'en', 'qui', 'il', 'a', 'le', 'plus', 'confiance', 'cest', 'son', 'meilleur', 'ami', 'mulot', ' ', 'ils', 'sont', 'inseparables', 'taupe', 'raffole', 'du', 'chocolat', 'et', 'de', 'la', 'tarte', 'aux', 'lombrics', 'mulot', 'est', 'joyeux', 'et', 'enthousiaste', 'applique', 'en', 'tout', 'parfois', 'un', 'peu', 'inquiet', 'aussi', 'il', 'a', 'toujours', 'le', 'bienetre', 'de', 'taupe', 'a', 'coeur', 'et', 'deploie', 'des', 'tresors', 'dimagination', 'pour', 'ne', 'jamais', 'froisser', 'son', 'meilleur', 'ami', 'il', 'vit', 'tout', 'pres', 'de', 'chez', 'lui', 'et', 'pas', 'un', 'jour', 'ne', 'se', 'passe', 'sans', 'quil', 'lui', 'rende', 'visite', 'avec', 'une', 'nouvelle', 'occupation', 'a', 'partager']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **üìå 4 : Suppression des stopwords**\n",
        "Enlever les mots tr√®s fr√©quents mais peu utiles (ex: \"le\", \"de\", \"et\") pour am√©liorer l‚Äôapprentissage de l‚ÄôIA."
      ],
      "metadata": {
        "id": "2FGy8uTo6o37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.lang.fr.stop_words import STOP_WORDS\n",
        "from tqdm import tqdm\n",
        "\n",
        "def remove_stopwords(tokens):\n",
        "    \"\"\"Supprime les stopwords de la liste de tokens.\"\"\"\n",
        "    return [word for word in tokens if word.lower() not in STOP_WORDS]\n",
        "\n",
        "# Appliquer la suppression des stopwords avec une barre de progression\n",
        "tqdm.pandas(desc=\"üßπ Suppression des stopwords\")\n",
        "df[\"tokens\"] = df[\"tokens\"].progress_apply(remove_stopwords)\n",
        "\n",
        "# V√©rifier les r√©sultats\n",
        "print(\"‚úÖ Exemple avant/apr√®s la suppression des stopwords :\\n\")\n",
        "print(\"Avant :\", df[\"tokens\"].iloc[0])\n",
        "print(\"Apr√®s :\", df[\"tokens\"].iloc[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZ5yiHi05c6C",
        "outputId": "3f6e00fa-35e3-44c2-9ac4-d366cbf066fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üßπ Suppression des stopwords: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 71213/71213 [00:01<00:00, 48424.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Exemple avant/apr√®s la suppression des stopwords :\n",
            "\n",
            "Avant : [' ', 'aaaaahhhh', '  ', 'mulot', ' ', 'mulot', ' ', 'ca', 'petit', 'imprudent', ' ', 'fois', 'taije', 'regarder', 'poses', 'pied', 'moimeme', '  ', ' ', 'cesse', 'plaisanter', 'taupe', 'crois', 'bien', 'casse', 'patte', 'taupe', 'mulot', 'saiment', 'differences', 'voient', 'jours', 'sentraident', 'partagent', 'gre', 'saisons', 'escalade', 'arbres', 'circuit', 'course', 'potager', 'bien', 'dautres', 'aventures', ' ', 'taupe', 'ny', 'voit', 'vraiment', 'grandchose', 'imagination', 'creativite', 'limites', 'ronchon', 'philosophe', 'confiance', 'cest', 'meilleur', 'ami', 'mulot', ' ', 'inseparables', 'taupe', 'raffole', 'chocolat', 'tarte', 'lombrics', 'mulot', 'joyeux', 'enthousiaste', 'applique', 'inquiet', 'bienetre', 'taupe', 'coeur', 'deploie', 'tresors', 'dimagination', 'jamais', 'froisser', 'meilleur', 'ami', 'vit', 'jour', 'passe', 'quil', 'rende', 'visite', 'nouvelle', 'occupation', 'partager']\n",
            "Apr√®s : [' ', 'aaaaahhhh', '  ', 'mulot', ' ', 'mulot', ' ', 'ca', 'petit', 'imprudent', ' ', 'fois', 'taije', 'regarder', 'poses', 'pied', 'moimeme', '  ', ' ', 'cesse', 'plaisanter', 'taupe', 'crois', 'bien', 'casse', 'patte', 'taupe', 'mulot', 'saiment', 'differences', 'voient', 'jours', 'sentraident', 'partagent', 'gre', 'saisons', 'escalade', 'arbres', 'circuit', 'course', 'potager', 'bien', 'dautres', 'aventures', ' ', 'taupe', 'ny', 'voit', 'vraiment', 'grandchose', 'imagination', 'creativite', 'limites', 'ronchon', 'philosophe', 'confiance', 'cest', 'meilleur', 'ami', 'mulot', ' ', 'inseparables', 'taupe', 'raffole', 'chocolat', 'tarte', 'lombrics', 'mulot', 'joyeux', 'enthousiaste', 'applique', 'inquiet', 'bienetre', 'taupe', 'coeur', 'deploie', 'tresors', 'dimagination', 'jamais', 'froisser', 'meilleur', 'ami', 'vit', 'jour', 'passe', 'quil', 'rende', 'visite', 'nouvelle', 'occupation', 'partager']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **üìå 5 : Lemmatisation**\n",
        "R√©duire les mots √† leur forme de base pour √©viter la r√©p√©tition inutile de variantes (ex: \"courir\", \"court\", \"courait\" deviennent \"courir\")."
      ],
      "metadata": {
        "id": "rNVBbgGE7Dho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lemmatize_tokens(tokens):\n",
        "    \"\"\"Applique la lemmatisation sur les tokens en utilisant spaCy.\"\"\"\n",
        "    doc = nlp(\" \".join(tokens))  # Reconvertir la liste en phrase pour traiter avec spaCy\n",
        "    return [token.lemma_ for token in doc]  # Retourner les lemmes\n",
        "\n",
        "# Appliquer la lemmatisation avec une barre de progression\n",
        "tqdm.pandas(desc=\"üîÑ Lemmatisation des tokens\")\n",
        "df[\"tokens\"] = df[\"tokens\"].progress_apply(lemmatize_tokens)\n",
        "\n",
        "# V√©rifier les r√©sultats\n",
        "print(\"‚úÖ Exemple avant/apr√®s la lemmatisation :\\n\")\n",
        "print(\"Avant :\", df[\"tokens\"].iloc[0])\n",
        "print(\"Apr√®s :\", df[\"tokens\"].iloc[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9hyE2Rm6p3O",
        "outputId": "a3d08b91-570a-4d53-c6a1-fec964226195"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üîÑ Lemmatisation des tokens: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 71213/71213 [20:20<00:00, 58.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Exemple avant/apr√®s la lemmatisation :\n",
            "\n",
            "Avant : ['  ', 'aaaaahhhh', '   ', 'mulot', '  ', 'mulot', '  ', 'ca', 'petit', 'impruder', '  ', 'fois', 'taije', 'regarder', 'pose', 'pied', 'moimeme', '     ', 'cesse', 'plaisanter', 'taupe', 'croire', 'bien', 'casse', 'patt', 'taupe', 'mulot', 'saiment', 'difference', 'voir', 'jour', 'sentraider', 'partager', 'gre', 'saison', 'escalad', 'arbre', 'circuit', 'cours', 'potager', 'bien', 'dautre', 'aventure', '  ', 'taupe', 'ny', 'voir', 'vraiment', 'grandchose', 'imagination', 'creativite', 'limite', 'ronchon', 'philosophe', 'confiance', 'cest', 'meilleur', 'ami', 'mulot', '  ', 'inseparable', 'taupe', 'raffol', 'chocolat', 'tarte', 'lombric', 'mulot', 'joyeux', 'enthousiaste', 'appliqu', 'inquiet', 'bienetre', 'taupe', 'coeur', 'deploi', 'tresor', 'dimagination', 'jamais', 'froisser', 'meilleur', 'ami', 'voir', 'jour', 'passer', 'quil', 'rend', 'visite', 'nouveau', 'occupation', 'partager']\n",
            "Apr√®s : ['  ', 'aaaaahhhh', '   ', 'mulot', '  ', 'mulot', '  ', 'ca', 'petit', 'impruder', '  ', 'fois', 'taije', 'regarder', 'pose', 'pied', 'moimeme', '     ', 'cesse', 'plaisanter', 'taupe', 'croire', 'bien', 'casse', 'patt', 'taupe', 'mulot', 'saiment', 'difference', 'voir', 'jour', 'sentraider', 'partager', 'gre', 'saison', 'escalad', 'arbre', 'circuit', 'cours', 'potager', 'bien', 'dautre', 'aventure', '  ', 'taupe', 'ny', 'voir', 'vraiment', 'grandchose', 'imagination', 'creativite', 'limite', 'ronchon', 'philosophe', 'confiance', 'cest', 'meilleur', 'ami', 'mulot', '  ', 'inseparable', 'taupe', 'raffol', 'chocolat', 'tarte', 'lombric', 'mulot', 'joyeux', 'enthousiaste', 'appliqu', 'inquiet', 'bienetre', 'taupe', 'coeur', 'deploi', 'tresor', 'dimagination', 'jamais', 'froisser', 'meilleur', 'ami', 'voir', 'jour', 'passer', 'quil', 'rend', 'visite', 'nouveau', 'occupation', 'partager']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **üìå 6 : Vectorisation des textes**\n",
        " Transformer les tokens en vecteurs num√©riques utilisables pour entra√Æner un mod√®le d'IA."
      ],
      "metadata": {
        "id": "oZ-hj3Ki7pkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Convertir les tokens en texte\n",
        "df[\"text_clean\"] = df[\"tokens\"].apply(lambda tokens: \" \".join(tokens))\n",
        "\n",
        "# Initialiser le vectoriseur TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # On limite √† 5000 features\n",
        "\n",
        "# Appliquer TF-IDF\n",
        "tqdm.pandas(desc=\"üî¢ Application du TF-IDF\")\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(df[\"text_clean\"].progress_apply(str))\n",
        "\n",
        "# V√©rifier la taille de la matrice\n",
        "print(\"‚úÖ Matrice TF-IDF cr√©√©e avec succ√®s !\")\n",
        "print(f\"üìè Dimensions : {tfidf_matrix.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azT3OulI7qFI",
        "outputId": "f5b278d9-971e-453f-fc28-5cb9828eae67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üî¢ Application du TF-IDF: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 71213/71213 [00:00<00:00, 662585.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Matrice TF-IDF cr√©√©e avec succ√®s !\n",
            "üìè Dimensions : (71213, 5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pourquoi utiliser TF-IDF ?**\n",
        "\n",
        "‚úî Pond√®re les mots en fonction de leur importance dans le corpus.\n",
        "\n",
        "‚úî Utile pour les mod√®les classiques de NLP (SVM, Na√Øve Bayes, etc.).\n",
        "\n",
        "‚úî R√©duit l‚Äôimpact des mots trop fr√©quents"
      ],
      "metadata": {
        "id": "vedH4jSg8C-0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **üìå 7 : Sauvegarde des r√©sultats**\n",
        "\n",
        "‚úî Enregistrer le dataset pr√©-trait√© en .csv."
      ],
      "metadata": {
        "id": "8plAJQuaBNMm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Enregistrer le dataset avec les tokens\n",
        "df.to_csv(\"livres_pretraite.csv\", index=False)\n",
        "\n",
        "print(\"‚úÖ Dataset pr√©-trait√© sauvegard√© en CSV avec succ√®s !\")\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "# T√©l√©charger le dataset pr√©-trait√©\n",
        "files.download(\"livres_pretraite.csv\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "nWwwGvk8Bd0t",
        "outputId": "847821a2-ff8d-4b5d-fbfa-61e39374f279"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Mod√®le Word2Vec sauvegard√© avec succ√®s !\n",
            "‚úÖ Dataset pr√©-trait√© sauvegard√© en CSV avec succ√®s !\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a29b5bc3-5b64-4494-ac12-c79a97808cda\", \"word2vec_books.model\", 68556257)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b2f7c298-85c8-471d-952d-3d0965bf620d\", \"livres_pretraite.csv\", 199586035)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}