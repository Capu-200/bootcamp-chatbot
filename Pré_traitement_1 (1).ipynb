{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **0️⃣. Installation** des bibliothèques"
      ],
      "metadata": {
        "id": "U_YGcZuBjZgi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "0. # Installer nltk (si nécessaire)\n",
        "!pip install nltk pandas\n",
        "\n",
        "1 # Importer les bibliothèques\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        " # Télécharger les ressources nltk (une seule fois)\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MT1D7JVmm503",
        "outputId": "b8416d23-9ef5-4314-a033-0afd0e7dfa45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "2# 📂 Demande à l'utilisateur de téléverser son fichier\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "EqlV4CShoyCb",
        "outputId": "e3222c68-623d-4186-d77d-85bc6f3c0fb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8c8a4b30-2bfc-47c4-9e40-6c858bb5d887\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8c8a4b30-2bfc-47c4-9e40-6c858bb5d887\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving livres_final_update_final avec auteur.xlsx to livres_final_update_final avec auteur (1).xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1️⃣ **Vérifier le fichier source (df.head())**\n",
        "🎯 **Objectif** : Regarder la structure du fichier et confirmer les colonnes existantes."
      ],
      "metadata": {
        "id": "lyYWVP89sbeX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Charger le fichier (remplace \"mon_fichier.csv\" par le vrai nom)\n",
        "df = pd.read_excel(\"livres_final_update_final avec auteur (1).xlsx\")\n",
        "\n",
        "# Vérifier les premières lignes\n",
        "print(\"🔍 Aperçu des données :\")\n",
        "print(df.head())\n",
        "\n",
        "# Vérifier les colonnes disponibles\n",
        "print(\"\\n📌 Colonnes disponibles :\")\n",
        "print(df.columns)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POpQbGAbpz6B",
        "outputId": "3f4b4e3f-53d4-4de8-ce03-a8ebc0ad3037"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Aperçu des données :\n",
            "                                           Titre             Auteur  \\\n",
            "0           Taupe & Mulot. Atteindre les sommets      Henri Meunier   \n",
            "1                   La guerre et la paix. Vol. 1       Léon Tolstoï   \n",
            "2                              L'âge de la forêt  Charline Collette   \n",
            "3  Des pas dans mon ciel bleu : CE1, série jaune  Nadine Brun-Cosme   \n",
            "4             10 bonnes raisons de te détester !         Emma Green   \n",
            "\n",
            "               Éditeur                                        Description  \\\n",
            "0               Hélium  - Aaaaahhhh... ! - Mulot ! Mulot ! Ça va, peti...   \n",
            "1            Gallimard  - Ah ! enlevez ces... enlevez donc ces... (Ell...   \n",
            "2         Joie de lire  - Alors le grand chêne est plus vieux que toi ...   \n",
            "3               Hatier  - Alors voilà, a conclu Papa en m'écartant trè...   \n",
            "4  Editions Addictives  - Arrête de te croire irrésistible, art. - Arr...   \n",
            "\n",
            "   Prix                                          Image URL  \\\n",
            "0  13.9  https://media.electre-ng.com/images/image-id/8...   \n",
            "1  10.5  https://media.electre-ng.com/images/image-id/3...   \n",
            "2  15.9  https://media.electre-ng.com/images/image-id/b...   \n",
            "3   4.2  https://media.electre-ng.com/images/image-id/4...   \n",
            "4  15.9  https://media.electre-ng.com/images/image-id/2...   \n",
            "\n",
            "                                                Lien  \\\n",
            "0  https://www.mollat.com/livres/2897100/henri-me...   \n",
            "1  https://www.mollat.com/livres/229752/leon-tols...   \n",
            "2  https://www.mollat.com/livres/2567474/charline...   \n",
            "3  https://www.mollat.com/livres/1520375/nadine-b...   \n",
            "4  https://www.mollat.com/livres/2408596/emma-gre...   \n",
            "\n",
            "                                     Catégorie  \n",
            "0                                     jeunesse  \n",
            "1  litterature-romanesque-historique-et-autres  \n",
            "2                                     jeunesse  \n",
            "3                                     scolaire  \n",
            "4  litterature-romanesque-historique-et-autres  \n",
            "\n",
            "📌 Colonnes disponibles :\n",
            "Index(['Titre', 'Auteur', 'Éditeur', 'Description', 'Prix', 'Image URL',\n",
            "       'Lien', 'Catégorie'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2️⃣**Ajouter une colonne \"Publication\"**\n",
        " 🎯 **Objectif** :\n",
        " Comme nous n'avons pas encore les années de publication, nous allons ajouter une colonne vide qui sera remplie plus tard avec l'API Google Books."
      ],
      "metadata": {
        "id": "sxwnObhds4mc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ajouter une colonne vide pour l'année de publication\n",
        "df[\"Publication\"] = None\n",
        "\n",
        "# Vérifier que la colonne a bien été ajoutée\n",
        "print(\"✅ Colonne 'Publication' ajoutée avec succès !\")\n",
        "print(df.head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CVH1pxitCNo",
        "outputId": "6ab4e3e5-41d4-40e6-d62a-2ea7d6689054"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Colonne 'Publication' ajoutée avec succès !\n",
            "                                           Titre             Auteur  \\\n",
            "0           Taupe & Mulot. Atteindre les sommets      Henri Meunier   \n",
            "1                   La guerre et la paix. Vol. 1       Léon Tolstoï   \n",
            "2                              L'âge de la forêt  Charline Collette   \n",
            "3  Des pas dans mon ciel bleu : CE1, série jaune  Nadine Brun-Cosme   \n",
            "4             10 bonnes raisons de te détester !         Emma Green   \n",
            "\n",
            "               Éditeur                                        Description  \\\n",
            "0               Hélium  - Aaaaahhhh... ! - Mulot ! Mulot ! Ça va, peti...   \n",
            "1            Gallimard  - Ah ! enlevez ces... enlevez donc ces... (Ell...   \n",
            "2         Joie de lire  - Alors le grand chêne est plus vieux que toi ...   \n",
            "3               Hatier  - Alors voilà, a conclu Papa en m'écartant trè...   \n",
            "4  Editions Addictives  - Arrête de te croire irrésistible, art. - Arr...   \n",
            "\n",
            "   Prix                                          Image URL  \\\n",
            "0  13.9  https://media.electre-ng.com/images/image-id/8...   \n",
            "1  10.5  https://media.electre-ng.com/images/image-id/3...   \n",
            "2  15.9  https://media.electre-ng.com/images/image-id/b...   \n",
            "3   4.2  https://media.electre-ng.com/images/image-id/4...   \n",
            "4  15.9  https://media.electre-ng.com/images/image-id/2...   \n",
            "\n",
            "                                                Lien  \\\n",
            "0  https://www.mollat.com/livres/2897100/henri-me...   \n",
            "1  https://www.mollat.com/livres/229752/leon-tols...   \n",
            "2  https://www.mollat.com/livres/2567474/charline...   \n",
            "3  https://www.mollat.com/livres/1520375/nadine-b...   \n",
            "4  https://www.mollat.com/livres/2408596/emma-gre...   \n",
            "\n",
            "                                     Catégorie Publication  \n",
            "0                                     jeunesse        None  \n",
            "1  litterature-romanesque-historique-et-autres        None  \n",
            "2                                     jeunesse        None  \n",
            "3                                     scolaire        None  \n",
            "4  litterature-romanesque-historique-et-autres        None  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3️⃣ **Utiliser l'API Google Books pour récupérer les auteurs inconnus**\n",
        "🎯 Objectif : Rechercher les livres avec \"Auteur inconnu\" dans la colonne \"Auteur\" et utiliser Google Books API pour trouver les vrais auteurs."
      ],
      "metadata": {
        "id": "NqL02nu6taOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import time\n",
        "\n",
        "# Clé API Google Books (remplace \"YOUR_API_KEY\" par ta clé)\n",
        "API_KEY = \"YOUR_API_KEY\"\n",
        "\n",
        "# URL de l'API Google Books\n",
        "GOOGLE_BOOKS_API_URL = \"https://www.googleapis.com/books/v1/volumes\"\n",
        "\n",
        "def get_book_info(title):\n",
        "    \"\"\"Recherche un livre sur Google Books et retourne l'auteur trouvé.\"\"\"\n",
        "    params = {\n",
        "        \"q\": f\"{title} livre\",\n",
        "        \"maxResults\": 1,\n",
        "        \"key\": API_KEY\n",
        "    }\n",
        "    response = requests.get(GOOGLE_BOOKS_API_URL, params=params)\n",
        "    data = response.json()\n",
        "\n",
        "    if \"items\" in data:\n",
        "        book_info = data[\"items\"][0][\"volumeInfo\"]\n",
        "        auteur = \", \".join(book_info.get(\"authors\", [\"Auteur inconnu\"]))\n",
        "        return auteur\n",
        "    return \"Auteur inconnu\"\n",
        "\n",
        "    # Début du chronomètre\n",
        "start_time = time.time()\n",
        "\n",
        "# Sélectionner uniquement les lignes où l'auteur est \"Auteur inconnu\"\n",
        "livres_sans_auteur = df[df[\"Auteur\"].str.lower() == \"auteur inconnu\"]\n",
        "\n",
        "# Barre de progression\n",
        "for index, row in tqdm(livres_sans_auteur.iterrows(), total=len(livres_sans_auteur), desc=\"🔄 Recherche des auteurs via API\"):\n",
        "    df.at[index, \"Auteur\"] = get_book_info(row[\"Titre\"])\n",
        "\n",
        "# Calcul du temps d'exécution\n",
        "elapsed_time = time.time() - start_time\n",
        "\n",
        "# Vérifier les résultats après mise à jour\n",
        "auteurs_trouves = df[df[\"Auteur\"].str.lower() != \"auteur inconnu\"]\n",
        "\n",
        "print(\"\\n✅ Mise à jour des auteurs terminée.\")\n",
        "print(f\"⏳ Temps total : {elapsed_time:.2f} secondes\")\n",
        "print(f\"📌 Nombre d'auteurs trouvés : {len(auteurs_trouves)}\")\n",
        "print(f\"📌 Nombre restant 'Auteur inconnu' : {len(df[df['Auteur'].str.lower() == 'auteur inconnu'])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itWlrupktd4B",
        "outputId": "8851a6ee-6cdf-4004-a2bf-584d0186e94c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🔄 Recherche des auteurs via API: 100%|██████████| 7983/7983 [02:31<00:00, 52.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Mise à jour des auteurs terminée.\n",
            "⏳ Temps total : 151.22 secondes\n",
            "📌 Nombre d'auteurs trouvés : 63230\n",
            "📌 Nombre restant 'Auteur inconnu' : 7983\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4️⃣ **Utiliser l'API Google Books pour récupérer les descriptions**\n",
        "🎯 **Objectif** : Remplacer les descriptions incorrectes (\"pas de description disponible\", \"expédié par\", etc.) par des résumés corrects à l’aide de Google Books API."
      ],
      "metadata": {
        "id": "AZDsoGEQv5WN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Renommer la colonne \"Description\" en \"Résumé\"\n",
        "df.rename(columns={\"Description\": \"Résumé\"}, inplace=True)\n",
        "\n",
        "# Vérifier le changement\n",
        "print(\"✅ La colonne 'Description' a été renommée en 'Résumé'\")\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnRfABKdwuma",
        "outputId": "616f2420-05ad-4755-a89d-62fa8093709e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ La colonne 'Description' a été renommée en 'Résumé'\n",
            "                                           Titre             Auteur  \\\n",
            "0           Taupe & Mulot. Atteindre les sommets      Henri Meunier   \n",
            "1                   La guerre et la paix. Vol. 1       Léon Tolstoï   \n",
            "2                              L'âge de la forêt  Charline Collette   \n",
            "3  Des pas dans mon ciel bleu : CE1, série jaune  Nadine Brun-Cosme   \n",
            "4             10 bonnes raisons de te détester !         Emma Green   \n",
            "\n",
            "               Éditeur                                             Résumé  \\\n",
            "0               Hélium  - Aaaaahhhh... ! - Mulot ! Mulot ! Ça va, peti...   \n",
            "1            Gallimard  - Ah ! enlevez ces... enlevez donc ces... (Ell...   \n",
            "2         Joie de lire  - Alors le grand chêne est plus vieux que toi ...   \n",
            "3               Hatier  - Alors voilà, a conclu Papa en m'écartant trè...   \n",
            "4  Editions Addictives  - Arrête de te croire irrésistible, art. - Arr...   \n",
            "\n",
            "   Prix                                          Image URL  \\\n",
            "0  13.9  https://media.electre-ng.com/images/image-id/8...   \n",
            "1  10.5  https://media.electre-ng.com/images/image-id/3...   \n",
            "2  15.9  https://media.electre-ng.com/images/image-id/b...   \n",
            "3   4.2  https://media.electre-ng.com/images/image-id/4...   \n",
            "4  15.9  https://media.electre-ng.com/images/image-id/2...   \n",
            "\n",
            "                                                Lien  \\\n",
            "0  https://www.mollat.com/livres/2897100/henri-me...   \n",
            "1  https://www.mollat.com/livres/229752/leon-tols...   \n",
            "2  https://www.mollat.com/livres/2567474/charline...   \n",
            "3  https://www.mollat.com/livres/1520375/nadine-b...   \n",
            "4  https://www.mollat.com/livres/2408596/emma-gre...   \n",
            "\n",
            "                                     Catégorie Publication  \n",
            "0                                     jeunesse        None  \n",
            "1  litterature-romanesque-historique-et-autres        None  \n",
            "2                                     jeunesse        None  \n",
            "3                                     scolaire        None  \n",
            "4  litterature-romanesque-historique-et-autres        None  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_book_summary(title, isbn=None):\n",
        "    \"\"\"Recherche un livre sur Google Books et retourne l'auteur et le résumé.\"\"\"\n",
        "\n",
        "    if isbn:\n",
        "        params = {\"q\": f\"isbn:{isbn}\", \"maxResults\": 1, \"key\": API_KEY}\n",
        "    else:\n",
        "        params = {\"q\": f\"{title} livre résumé\", \"maxResults\": 1, \"key\": API_KEY}\n",
        "\n",
        "    response = requests.get(GOOGLE_BOOKS_API_URL, params=params)\n",
        "    data = response.json()\n",
        "\n",
        "    if \"items\" in data:\n",
        "        book_info = data[\"items\"][0][\"volumeInfo\"]\n",
        "        auteur = \", \".join(book_info.get(\"authors\", [\"Auteur inconnu\"]))\n",
        "        resume = book_info.get(\"description\", \"Résumé non disponible\")\n",
        "        return auteur, resume\n",
        "\n",
        "    return \"Auteur inconnu\", \"Résumé non disponible\"\n",
        "# Début du chronomètre\n",
        "start_time = time.time()\n",
        "\n",
        "# Liste des valeurs à remplacer dans la colonne \"Résumé\"\n",
        "descriptions_vides = [\"description non disponible\", \"expédié par\", \"pas de description disponible\"]\n",
        "\n",
        "# Sélectionner uniquement les lignes où le résumé est incorrect\n",
        "livres_sans_resume = df[df[\"Résumé\"].str.lower().isin(descriptions_vides)]\n",
        "\n",
        "# Barre de progression\n",
        "for index, row in tqdm(livres_sans_resume.iterrows(), total=len(livres_sans_resume), desc=\"📖 Recherche des résumés via API\"):\n",
        "    isbn = row[\"ISBN\"] if \"ISBN\" in df.columns and pd.notna(row[\"ISBN\"]) else None\n",
        "    _, resume = get_book_summary(row[\"Titre\"], isbn)\n",
        "    df.at[index, \"Résumé\"] = resume\n",
        "\n",
        "# Calcul du temps d'exécution\n",
        "elapsed_time = time.time() - start_time\n",
        "\n",
        "# Vérifier les résultats après mise à jour\n",
        "resumes_restants = df[df[\"Résumé\"].str.lower().isin(descriptions_vides)]\n",
        "\n",
        "print(\"\\n✅ Mise à jour des résumés terminée.\")\n",
        "print(f\"⏳ Temps total : {elapsed_time:.2f} secondes\")\n",
        "print(f\"📌 Nombre restant 'Résumé non disponible' après mise à jour : {len(resumes_restants)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "athoqdpUXdWl",
        "outputId": "28dce934-643e-496d-c028-12a7c5fad439"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "📖 Recherche des résumés via API: 100%|██████████| 1771/1771 [00:30<00:00, 58.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Mise à jour des résumés terminée.\n",
            "⏳ Temps total : 30.85 secondes\n",
            "📌 Nombre restant 'Résumé non disponible' après mise à jour : 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5️⃣**Utiliser l'API Google Books pour récupérer les dates de publication**\n",
        "🎯 **Objectif** : Remplacer les valeurs None dans la colonne \"Publication\" par la vraie année de publication grâce à l’API Google Books."
      ],
      "metadata": {
        "id": "9oHnQ6gvxZQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_book_details(title, isbn=None):\n",
        "    \"\"\"Recherche un livre sur Google Books et retourne l'auteur, le résumé et la date de publication.\"\"\"\n",
        "\n",
        "    if isbn:\n",
        "        params = {\"q\": f\"isbn:{isbn}\", \"maxResults\": 1, \"key\": API_KEY}\n",
        "    else:\n",
        "        params = {\"q\": f\"{title} livre\", \"maxResults\": 1, \"key\": API_KEY}\n",
        "\n",
        "    response = requests.get(GOOGLE_BOOKS_API_URL, params=params)\n",
        "    data = response.json()\n",
        "\n",
        "    if \"items\" in data:\n",
        "        book_info = data[\"items\"][0][\"volumeInfo\"]\n",
        "        auteur = \", \".join(book_info.get(\"authors\", [\"Auteur inconnu\"]))\n",
        "        resume = book_info.get(\"description\", \"Résumé non disponible\")\n",
        "        date_publication = book_info.get(\"publishedDate\", \"Date inconnue\")\n",
        "        return auteur, resume, date_publication\n",
        "\n",
        "    return \"Auteur inconnu\", \"Résumé non disponible\", \"Date inconnue\"\n",
        "\n",
        "# Début du chronomètre\n",
        "start_time = time.time()\n",
        "\n",
        "# Sélectionner uniquement les lignes où la date de publication est \"None\" ou \"Date inconnue\"\n",
        "livres_sans_date = df[df[\"Publication\"].isna() | (df[\"Publication\"] == \"Date inconnue\")]\n",
        "\n",
        "# Barre de progression\n",
        "for index, row in tqdm(livres_sans_date.iterrows(), total=len(livres_sans_date), desc=\"📅 Recherche des dates de publication via API\"):\n",
        "    isbn = row[\"ISBN\"] if \"ISBN\" in df.columns and pd.notna(row[\"ISBN\"]) else None\n",
        "    _, _, date_publication = get_book_details(row[\"Titre\"], isbn)\n",
        "    df.at[index, \"Publication\"] = date_publication\n",
        "\n",
        "# Calcul du temps d'exécution\n",
        "elapsed_time = time.time() - start_time\n",
        "\n",
        "# Vérifier les résultats après mise à jour\n",
        "dates_restantes = df[df[\"Publication\"].isna() | (df[\"Publication\"] == \"Date inconnue\")]\n",
        "\n",
        "print(\"\\n✅ Mise à jour des dates terminée.\")\n",
        "print(f\"⏳ Temps total : {elapsed_time:.2f} secondes\")\n",
        "print(f\"📌 Nombre restant 'Date inconnue' après mise à jour : {len(dates_restantes)}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkAdlhhyxg8S",
        "outputId": "2ddce7c0-5f30-4580-905c-f8ab1b156eea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "📅 Recherche des dates de publication via API: 100%|██████████| 71213/71213 [22:04<00:00, 53.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Mise à jour des dates terminée.\n",
            "⏳ Temps total : 1324.48 secondes\n",
            "📌 Nombre restant 'Date inconnue' après mise à jour : 71213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vérifier les premiers livres avec \"Date inconnue\"\n",
        "print(\"\\n📌 Exemples de livres sans date trouvée :\")\n",
        "print(df[df[\"Publication\"] == \"Date inconnue\"].head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqwTqAlGf2QH",
        "outputId": "0a52e9f5-cab2-4056-a132-4f417f0181d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📌 Exemples de livres sans date trouvée :\n",
            "                                            Titre             Auteur  \\\n",
            "0            Taupe & Mulot. Atteindre les sommets      Henri Meunier   \n",
            "1                    La guerre et la paix. Vol. 1       Léon Tolstoï   \n",
            "2                               L'âge de la forêt  Charline Collette   \n",
            "3   Des pas dans mon ciel bleu : CE1, série jaune  Nadine Brun-Cosme   \n",
            "4              10 bonnes raisons de te détester !         Emma Green   \n",
            "5                              La flûte enchantée       Pierre Coran   \n",
            "6                                     Le bonhomme  Stephen Vuillemin   \n",
            "7                                       Oui & non      Elisha Cooper   \n",
            "8               Comment on construit une maison ?        César Canet   \n",
            "9  Vie et mort de l'homme qui tua John F. Kennedy  Anne-James Chaton   \n",
            "\n",
            "                  Éditeur                                             Résumé  \\\n",
            "0                  Hélium  - Aaaaahhhh... ! - Mulot ! Mulot ! Ça va, peti...   \n",
            "1               Gallimard  - Ah ! enlevez ces... enlevez donc ces... (Ell...   \n",
            "2            Joie de lire  - Alors le grand chêne est plus vieux que toi ...   \n",
            "3                  Hatier  - Alors voilà, a conclu Papa en m'écartant trè...   \n",
            "4     Editions Addictives  - Arrête de te croire irrésistible, art. - Arr...   \n",
            "5  Père Castor-Flammarion  - Bienvenue, Tamino ! dit la belle Pamina. Sai...   \n",
            "6   Albin Michel-Jeunesse  - Bonhomme, nous voulons nous déguiser en dino...   \n",
            "7            Le Genévrier  - Bonjour, bonjour ! C'est l'heure de se lever...   \n",
            "8    Poids Plume éditions  - C'est vrai ça ! Comment on construit une mai...   \n",
            "9                     POL  - Ça venait d'où ? - Ils l'ont tué. - Vous ave...   \n",
            "\n",
            "   Prix                                          Image URL  \\\n",
            "0  13.9  https://media.electre-ng.com/images/image-id/8...   \n",
            "1  10.5  https://media.electre-ng.com/images/image-id/3...   \n",
            "2  15.9  https://media.electre-ng.com/images/image-id/b...   \n",
            "3   4.2  https://media.electre-ng.com/images/image-id/4...   \n",
            "4  15.9  https://media.electre-ng.com/images/image-id/2...   \n",
            "5  13.5  https://media.electre-ng.com/images/image-id/f...   \n",
            "6    18  https://media.electre-ng.com/images/image-id/8...   \n",
            "7    13  https://media.electre-ng.com/images/image-id/1...   \n",
            "8  14.5  https://media.electre-ng.com/images/image-id/9...   \n",
            "9  18.9  https://media.electre-ng.com/images/image-id/e...   \n",
            "\n",
            "                                                Lien  \\\n",
            "0  https://www.mollat.com/livres/2897100/henri-me...   \n",
            "1  https://www.mollat.com/livres/229752/leon-tols...   \n",
            "2  https://www.mollat.com/livres/2567474/charline...   \n",
            "3  https://www.mollat.com/livres/1520375/nadine-b...   \n",
            "4  https://www.mollat.com/livres/2408596/emma-gre...   \n",
            "5  https://www.mollat.com/livres/995822/pierre-co...   \n",
            "6  https://www.mollat.com/livres/3139513/stephen-...   \n",
            "7  https://www.mollat.com/livres/2493370/elisha-c...   \n",
            "8  https://www.mollat.com/livres/2945155/cesar-ca...   \n",
            "9  https://www.mollat.com/livres/2406311/anne-jam...   \n",
            "\n",
            "                                     Catégorie    Publication  \n",
            "0                                     jeunesse  Date inconnue  \n",
            "1  litterature-romanesque-historique-et-autres  Date inconnue  \n",
            "2                                     jeunesse  Date inconnue  \n",
            "3                                     scolaire  Date inconnue  \n",
            "4  litterature-romanesque-historique-et-autres  Date inconnue  \n",
            "5                                     jeunesse  Date inconnue  \n",
            "6                                     jeunesse  Date inconnue  \n",
            "7                                     jeunesse  Date inconnue  \n",
            "8                                     jeunesse  Date inconnue  \n",
            "9                     biographies-beaux-livres  Date inconnue  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def get_book_year(title, isbn=None):\n",
        "    \"\"\"Recherche un livre sur Google Books et retourne l'année de publication.\"\"\"\n",
        "\n",
        "    if isbn:\n",
        "        params = {\"q\": f\"isbn:{isbn}\", \"maxResults\": 1, \"key\": API_KEY}\n",
        "    else:\n",
        "        params = {\"q\": f\"{title} livre\", \"maxResults\": 1, \"key\": API_KEY}\n",
        "\n",
        "    response = requests.get(GOOGLE_BOOKS_API_URL, params=params)\n",
        "    data = response.json()\n",
        "\n",
        "    if \"items\" in data:\n",
        "        book_info = data[\"items\"][0][\"volumeInfo\"]\n",
        "        date_publication = book_info.get(\"publishedDate\", \"Date inconnue\")\n",
        "\n",
        "        # Extraire uniquement l'année si un format plus long est trouvé\n",
        "        match = re.search(r\"\\d{4}\", date_publication)  # Recherche une année (4 chiffres)\n",
        "        if match:\n",
        "            return match.group(0)  # Retourne uniquement l'année\n",
        "\n",
        "    return \"Date inconnue\"\n",
        "\n",
        "# Début du chronomètre\n",
        "start_time = time.time()\n",
        "\n",
        "# Sélectionner uniquement les lignes où la date est \"Date inconnue\" ou \"non\"\n",
        "livres_sans_date = df[df[\"Publication\"].isna() | (df[\"Publication\"].str.lower() == \"non\") | (df[\"Publication\"] == \"Date inconnue\")]\n",
        "\n",
        "# Barre de progression\n",
        "for index, row in tqdm(livres_sans_date.iterrows(), total=len(livres_sans_date), desc=\"📅 Recherche des années de publication via API\"):\n",
        "    isbn = row[\"ISBN\"] if \"ISBN\" in df.columns and pd.notna(row[\"ISBN\"]) else None\n",
        "    year = get_book_year(row[\"Titre\"], isbn)\n",
        "    df.at[index, \"Publication\"] = year\n",
        "\n",
        "# Calcul du temps d'exécution\n",
        "elapsed_time = time.time() - start_time\n",
        "\n",
        "# Vérifier les résultats après mise à jour\n",
        "dates_restantes = df[df[\"Publication\"] == \"Date inconnue\"]\n",
        "\n",
        "print(\"\\n✅ Mise à jour des années terminée.\")\n",
        "print(f\"⏳ Temps total : {elapsed_time:.2f} secondes\")\n",
        "print(f\"📌 Nombre restant 'Date inconnue' après mise à jour : {len(dates_restantes)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ipJiJIofNtz",
        "outputId": "913c5ad1-8781-4f86-eb1d-e96df4650ca1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "📅 Recherche des années de publication via API: 100%|██████████| 71213/71213 [22:13<00:00, 53.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Mise à jour des années terminée.\n",
            "⏳ Temps total : 1333.57 secondes\n",
            "📌 Nombre restant 'Date inconnue' après mise à jour : 71213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Supprimer la colonne \"Publication\"\n",
        "df.drop(columns=[\"Publication\"], inplace=True)\n",
        "\n",
        "# Vérifier que la colonne a bien été supprimée\n",
        "print(\"✅ Colonne 'Publication' supprimée avec succès !\")\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROL8sImZucIE",
        "outputId": "0ad38cb0-d424-4c56-968b-aa40c2ace008"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Colonne 'Publication' supprimée avec succès !\n",
            "                                           Titre             Auteur  \\\n",
            "0           Taupe & Mulot. Atteindre les sommets      Henri Meunier   \n",
            "1                   La guerre et la paix. Vol. 1       Léon Tolstoï   \n",
            "2                              L'âge de la forêt  Charline Collette   \n",
            "3  Des pas dans mon ciel bleu : CE1, série jaune  Nadine Brun-Cosme   \n",
            "4             10 bonnes raisons de te détester !         Emma Green   \n",
            "\n",
            "               Éditeur                                             Résumé  \\\n",
            "0               Hélium  - Aaaaahhhh... ! - Mulot ! Mulot ! Ça va, peti...   \n",
            "1            Gallimard  - Ah ! enlevez ces... enlevez donc ces... (Ell...   \n",
            "2         Joie de lire  - Alors le grand chêne est plus vieux que toi ...   \n",
            "3               Hatier  - Alors voilà, a conclu Papa en m'écartant trè...   \n",
            "4  Editions Addictives  - Arrête de te croire irrésistible, art. - Arr...   \n",
            "\n",
            "   Prix                                          Image URL  \\\n",
            "0  13.9  https://media.electre-ng.com/images/image-id/8...   \n",
            "1  10.5  https://media.electre-ng.com/images/image-id/3...   \n",
            "2  15.9  https://media.electre-ng.com/images/image-id/b...   \n",
            "3   4.2  https://media.electre-ng.com/images/image-id/4...   \n",
            "4  15.9  https://media.electre-ng.com/images/image-id/2...   \n",
            "\n",
            "                                                Lien  \\\n",
            "0  https://www.mollat.com/livres/2897100/henri-me...   \n",
            "1  https://www.mollat.com/livres/229752/leon-tols...   \n",
            "2  https://www.mollat.com/livres/2567474/charline...   \n",
            "3  https://www.mollat.com/livres/1520375/nadine-b...   \n",
            "4  https://www.mollat.com/livres/2408596/emma-gre...   \n",
            "\n",
            "                                     Catégorie  \n",
            "0                                     jeunesse  \n",
            "1  litterature-romanesque-historique-et-autres  \n",
            "2                                     jeunesse  \n",
            "3                                     scolaire  \n",
            "4  litterature-romanesque-historique-et-autres  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **📌 Plan des étapes pour le NLP Processing**\n",
        "1️⃣ **Normaliser le texte** : suppression des accents, mise en minuscules\n",
        "\n",
        "2️⃣ **Tokenisation** : découper les textes en mots\n",
        "\n",
        "3️⃣ **Suppression des stopwords** : mots non significatifs comme \"le\", \"de\", \"et\"\n",
        "\n",
        "4️⃣ **Lemmatisation** : réduction des mots à leur forme de base : \"manger\" → \"mangé\"\n",
        "\n",
        "5️⃣ **Vectorisation** TF-IDF\n",
        "\n",
        "6️⃣ **Export** du fichier final pour l’entraînement IA."
      ],
      "metadata": {
        "id": "96ej3kGcs1Ol"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **📌 1 : Mise en minuscule et suppression des accents**\n",
        "Convertir tout le texte en minuscules et remplacer les lettres accentuées sans les supprimer."
      ],
      "metadata": {
        "id": "6zq4UyivwR9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import unicodedata\n",
        "\n",
        "def normalize_text(text):\n",
        "    \"\"\"Met en minuscule et enlève les accents du texte.\"\"\"\n",
        "    text = str(text).lower()  # Mise en minuscule\n",
        "    text = unicodedata.normalize(\"NFD\", text).encode(\"ascii\", \"ignore\").decode(\"utf-8\")  # Suppression des accents\n",
        "    return text\n",
        "\n",
        "# Appliquer le nettoyage sur les titres et résumés\n",
        "df[\"Titre_clean\"] = df[\"Titre\"].apply(normalize_text)\n",
        "df[\"Résumé_clean\"] = df[\"Résumé\"].apply(normalize_text)\n",
        "\n",
        "# Vérifier le résultat\n",
        "print(\"✅ Exemple avant/après la normalisation :\\n\")\n",
        "print(\"Avant :\", df[\"Titre\"].iloc[0])\n",
        "print(\"Après :\", df[\"Titre_clean\"].iloc[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klZT4VaXtn2H",
        "outputId": "d1d250ab-a03c-4fd3-e07d-de236b1415f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Exemple avant/après la normalisation :\n",
            "\n",
            "Avant : Taupe & Mulot. Atteindre les sommets\n",
            "Après : taupe & mulot. atteindre les sommets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📌 **2 : Suppression des symboles mais conservation des nombres**\n",
        "✔ Supprimer la ponctuation et les symboles.\n",
        "✔ Conserver les nombres (dates, références utiles)."
      ],
      "metadata": {
        "id": "l0wU58glw5gz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def remove_punctuation_keep_numbers(text):\n",
        "    \"\"\"Supprime la ponctuation et les symboles spéciaux, mais garde les nombres.\"\"\"\n",
        "    text = re.sub(r\"[^\\w\\s\\d]\", \"\", text)  # Supprime la ponctuation mais garde les nombres\n",
        "    return text\n",
        "\n",
        "# Appliquer le nettoyage sur les colonnes\n",
        "df[\"Titre_clean\"] = df[\"Titre_clean\"].apply(remove_punctuation_keep_numbers)\n",
        "df[\"Résumé_clean\"] = df[\"Résumé_clean\"].apply(remove_punctuation_keep_numbers)\n",
        "\n",
        "# Vérifier le résultat\n",
        "print(\"✅ Exemple avant/après suppression des symboles (mais conservation des nombres) :\\n\")\n",
        "print(\"Avant :\", df[\"Titre\"].iloc[0])\n",
        "print(\"Après :\", df[\"Titre_clean\"].iloc[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cdfzm8pKw_7Y",
        "outputId": "5b373863-5fb4-48b0-d79b-c6de800dcd27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Exemple avant/après suppression des symboles (mais conservation des nombres) :\n",
            "\n",
            "Avant : Taupe & Mulot. Atteindre les sommets\n",
            "Après : taupe  mulot atteindre les sommets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📌**3 : Découpage du texte en mots (Tokenisation)**\n",
        "Transformer le texte en une liste de mots (tokens) pour l’analyse NLP.\n",
        "\n",
        "✔ Facilite l’analyse de chaque mot indépendamment.\n",
        "\n",
        "✔ Prépare les données pour des modèles d’IA (TF-IDF)."
      ],
      "metadata": {
        "id": "ywO5Z1ZixR1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download fr_core_news_sm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2YidNaHyW7M",
        "outputId": "3c11fb1f-69d3-4183-cbe5-d4a30c3f8199"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.12.14)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting fr-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.7.0/fr_core_news_sm-3.7.0-py3-none-any.whl (16.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from fr-core-news-sm==3.7.0) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.2.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2024.12.14)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.1.2)\n",
            "Installing collected packages: fr-core-news-sm\n",
            "Successfully installed fr-core-news-sm-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Charger le modèle français\n",
        "nlp = spacy.load(\"fr_core_news_sm\")\n",
        "\n",
        "def tokenize_text(text):\n",
        "    \"\"\"Tokenise un texte avec spacy\"\"\"\n",
        "    doc = nlp(text)\n",
        "    return [token.text for token in doc]\n",
        "\n",
        "# Appliquer la tokenisation avec une barre de progression\n",
        "tqdm.pandas(desc=\"🔄 Tokenisation des résumés\")\n",
        "df[\"tokens\"] = df[\"Résumé_clean\"].progress_apply(tokenize_text)\n",
        "\n",
        "# Vérifier les résultats\n",
        "print(\"✅ Exemple avant/après la tokenisation :\\n\")\n",
        "print(\"Avant :\", df[\"Résumé_clean\"].iloc[0])\n",
        "print(\"Après :\", df[\"tokens\"].iloc[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMyM1kLsy4fR",
        "outputId": "820728ea-0353-401d-e099-b0165aaabc4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🔄 Tokenisation des résumés: 100%|██████████| 71213/71213 [31:48<00:00, 37.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Exemple avant/après la tokenisation :\n",
            "\n",
            "Avant :  aaaaahhhh   mulot  mulot  ca va petit imprudent  combien de fois taije dit de toujours regarder ou tu poses le pied comme je le fais moimeme   aie aie aie  cesse donc de plaisanter taupe je crois bien que je me suis casse la patte taupe et mulot saiment plus que tout malgre leurs differences ils se voient tous les jours sentraident et partagent au gre des saisons escalade dans les arbres circuit de course dans le potager et bien dautres aventures  taupe ny voit vraiment pas grandchose mais son imagination et sa creativite sont sans limites il est un peu ronchon mais assez philosophe la personne en qui il a le plus confiance cest son meilleur ami mulot  ils sont inseparables taupe raffole du chocolat et de la tarte aux lombrics mulot est joyeux et enthousiaste applique en tout parfois un peu inquiet aussi il a toujours le bienetre de taupe a coeur et deploie des tresors dimagination pour ne jamais froisser son meilleur ami il vit tout pres de chez lui et pas un jour ne se passe sans quil lui rende visite avec une nouvelle occupation a partager\n",
            "Après : [' ', 'aaaaahhhh', '  ', 'mulot', ' ', 'mulot', ' ', 'ca', 'va', 'petit', 'imprudent', ' ', 'combien', 'de', 'fois', 'taije', 'dit', 'de', 'toujours', 'regarder', 'ou', 'tu', 'poses', 'le', 'pied', 'comme', 'je', 'le', 'fais', 'moimeme', '  ', 'aie', 'aie', 'aie', ' ', 'cesse', 'donc', 'de', 'plaisanter', 'taupe', 'je', 'crois', 'bien', 'que', 'je', 'me', 'suis', 'casse', 'la', 'patte', 'taupe', 'et', 'mulot', 'saiment', 'plus', 'que', 'tout', 'malgre', 'leurs', 'differences', 'ils', 'se', 'voient', 'tous', 'les', 'jours', 'sentraident', 'et', 'partagent', 'au', 'gre', 'des', 'saisons', 'escalade', 'dans', 'les', 'arbres', 'circuit', 'de', 'course', 'dans', 'le', 'potager', 'et', 'bien', 'dautres', 'aventures', ' ', 'taupe', 'ny', 'voit', 'vraiment', 'pas', 'grandchose', 'mais', 'son', 'imagination', 'et', 'sa', 'creativite', 'sont', 'sans', 'limites', 'il', 'est', 'un', 'peu', 'ronchon', 'mais', 'assez', 'philosophe', 'la', 'personne', 'en', 'qui', 'il', 'a', 'le', 'plus', 'confiance', 'cest', 'son', 'meilleur', 'ami', 'mulot', ' ', 'ils', 'sont', 'inseparables', 'taupe', 'raffole', 'du', 'chocolat', 'et', 'de', 'la', 'tarte', 'aux', 'lombrics', 'mulot', 'est', 'joyeux', 'et', 'enthousiaste', 'applique', 'en', 'tout', 'parfois', 'un', 'peu', 'inquiet', 'aussi', 'il', 'a', 'toujours', 'le', 'bienetre', 'de', 'taupe', 'a', 'coeur', 'et', 'deploie', 'des', 'tresors', 'dimagination', 'pour', 'ne', 'jamais', 'froisser', 'son', 'meilleur', 'ami', 'il', 'vit', 'tout', 'pres', 'de', 'chez', 'lui', 'et', 'pas', 'un', 'jour', 'ne', 'se', 'passe', 'sans', 'quil', 'lui', 'rende', 'visite', 'avec', 'une', 'nouvelle', 'occupation', 'a', 'partager']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **📌 4 : Suppression des stopwords**\n",
        "Enlever les mots très fréquents mais peu utiles (ex: \"le\", \"de\", \"et\") pour améliorer l’apprentissage de l’IA."
      ],
      "metadata": {
        "id": "2FGy8uTo6o37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.lang.fr.stop_words import STOP_WORDS\n",
        "from tqdm import tqdm\n",
        "\n",
        "def remove_stopwords(tokens):\n",
        "    \"\"\"Supprime les stopwords de la liste de tokens.\"\"\"\n",
        "    return [word for word in tokens if word.lower() not in STOP_WORDS]\n",
        "\n",
        "# Appliquer la suppression des stopwords avec une barre de progression\n",
        "tqdm.pandas(desc=\"🧹 Suppression des stopwords\")\n",
        "df[\"tokens\"] = df[\"tokens\"].progress_apply(remove_stopwords)\n",
        "\n",
        "# Vérifier les résultats\n",
        "print(\"✅ Exemple avant/après la suppression des stopwords :\\n\")\n",
        "print(\"Avant :\", df[\"tokens\"].iloc[0])\n",
        "print(\"Après :\", df[\"tokens\"].iloc[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZ5yiHi05c6C",
        "outputId": "3f6e00fa-35e3-44c2-9ac4-d366cbf066fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🧹 Suppression des stopwords: 100%|██████████| 71213/71213 [00:01<00:00, 48424.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Exemple avant/après la suppression des stopwords :\n",
            "\n",
            "Avant : [' ', 'aaaaahhhh', '  ', 'mulot', ' ', 'mulot', ' ', 'ca', 'petit', 'imprudent', ' ', 'fois', 'taije', 'regarder', 'poses', 'pied', 'moimeme', '  ', ' ', 'cesse', 'plaisanter', 'taupe', 'crois', 'bien', 'casse', 'patte', 'taupe', 'mulot', 'saiment', 'differences', 'voient', 'jours', 'sentraident', 'partagent', 'gre', 'saisons', 'escalade', 'arbres', 'circuit', 'course', 'potager', 'bien', 'dautres', 'aventures', ' ', 'taupe', 'ny', 'voit', 'vraiment', 'grandchose', 'imagination', 'creativite', 'limites', 'ronchon', 'philosophe', 'confiance', 'cest', 'meilleur', 'ami', 'mulot', ' ', 'inseparables', 'taupe', 'raffole', 'chocolat', 'tarte', 'lombrics', 'mulot', 'joyeux', 'enthousiaste', 'applique', 'inquiet', 'bienetre', 'taupe', 'coeur', 'deploie', 'tresors', 'dimagination', 'jamais', 'froisser', 'meilleur', 'ami', 'vit', 'jour', 'passe', 'quil', 'rende', 'visite', 'nouvelle', 'occupation', 'partager']\n",
            "Après : [' ', 'aaaaahhhh', '  ', 'mulot', ' ', 'mulot', ' ', 'ca', 'petit', 'imprudent', ' ', 'fois', 'taije', 'regarder', 'poses', 'pied', 'moimeme', '  ', ' ', 'cesse', 'plaisanter', 'taupe', 'crois', 'bien', 'casse', 'patte', 'taupe', 'mulot', 'saiment', 'differences', 'voient', 'jours', 'sentraident', 'partagent', 'gre', 'saisons', 'escalade', 'arbres', 'circuit', 'course', 'potager', 'bien', 'dautres', 'aventures', ' ', 'taupe', 'ny', 'voit', 'vraiment', 'grandchose', 'imagination', 'creativite', 'limites', 'ronchon', 'philosophe', 'confiance', 'cest', 'meilleur', 'ami', 'mulot', ' ', 'inseparables', 'taupe', 'raffole', 'chocolat', 'tarte', 'lombrics', 'mulot', 'joyeux', 'enthousiaste', 'applique', 'inquiet', 'bienetre', 'taupe', 'coeur', 'deploie', 'tresors', 'dimagination', 'jamais', 'froisser', 'meilleur', 'ami', 'vit', 'jour', 'passe', 'quil', 'rende', 'visite', 'nouvelle', 'occupation', 'partager']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **📌 5 : Lemmatisation**\n",
        "Réduire les mots à leur forme de base pour éviter la répétition inutile de variantes (ex: \"courir\", \"court\", \"courait\" deviennent \"courir\")."
      ],
      "metadata": {
        "id": "rNVBbgGE7Dho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lemmatize_tokens(tokens):\n",
        "    \"\"\"Applique la lemmatisation sur les tokens en utilisant spaCy.\"\"\"\n",
        "    doc = nlp(\" \".join(tokens))  # Reconvertir la liste en phrase pour traiter avec spaCy\n",
        "    return [token.lemma_ for token in doc]  # Retourner les lemmes\n",
        "\n",
        "# Appliquer la lemmatisation avec une barre de progression\n",
        "tqdm.pandas(desc=\"🔄 Lemmatisation des tokens\")\n",
        "df[\"tokens\"] = df[\"tokens\"].progress_apply(lemmatize_tokens)\n",
        "\n",
        "# Vérifier les résultats\n",
        "print(\"✅ Exemple avant/après la lemmatisation :\\n\")\n",
        "print(\"Avant :\", df[\"tokens\"].iloc[0])\n",
        "print(\"Après :\", df[\"tokens\"].iloc[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9hyE2Rm6p3O",
        "outputId": "a3d08b91-570a-4d53-c6a1-fec964226195"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🔄 Lemmatisation des tokens: 100%|██████████| 71213/71213 [20:20<00:00, 58.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Exemple avant/après la lemmatisation :\n",
            "\n",
            "Avant : ['  ', 'aaaaahhhh', '   ', 'mulot', '  ', 'mulot', '  ', 'ca', 'petit', 'impruder', '  ', 'fois', 'taije', 'regarder', 'pose', 'pied', 'moimeme', '     ', 'cesse', 'plaisanter', 'taupe', 'croire', 'bien', 'casse', 'patt', 'taupe', 'mulot', 'saiment', 'difference', 'voir', 'jour', 'sentraider', 'partager', 'gre', 'saison', 'escalad', 'arbre', 'circuit', 'cours', 'potager', 'bien', 'dautre', 'aventure', '  ', 'taupe', 'ny', 'voir', 'vraiment', 'grandchose', 'imagination', 'creativite', 'limite', 'ronchon', 'philosophe', 'confiance', 'cest', 'meilleur', 'ami', 'mulot', '  ', 'inseparable', 'taupe', 'raffol', 'chocolat', 'tarte', 'lombric', 'mulot', 'joyeux', 'enthousiaste', 'appliqu', 'inquiet', 'bienetre', 'taupe', 'coeur', 'deploi', 'tresor', 'dimagination', 'jamais', 'froisser', 'meilleur', 'ami', 'voir', 'jour', 'passer', 'quil', 'rend', 'visite', 'nouveau', 'occupation', 'partager']\n",
            "Après : ['  ', 'aaaaahhhh', '   ', 'mulot', '  ', 'mulot', '  ', 'ca', 'petit', 'impruder', '  ', 'fois', 'taije', 'regarder', 'pose', 'pied', 'moimeme', '     ', 'cesse', 'plaisanter', 'taupe', 'croire', 'bien', 'casse', 'patt', 'taupe', 'mulot', 'saiment', 'difference', 'voir', 'jour', 'sentraider', 'partager', 'gre', 'saison', 'escalad', 'arbre', 'circuit', 'cours', 'potager', 'bien', 'dautre', 'aventure', '  ', 'taupe', 'ny', 'voir', 'vraiment', 'grandchose', 'imagination', 'creativite', 'limite', 'ronchon', 'philosophe', 'confiance', 'cest', 'meilleur', 'ami', 'mulot', '  ', 'inseparable', 'taupe', 'raffol', 'chocolat', 'tarte', 'lombric', 'mulot', 'joyeux', 'enthousiaste', 'appliqu', 'inquiet', 'bienetre', 'taupe', 'coeur', 'deploi', 'tresor', 'dimagination', 'jamais', 'froisser', 'meilleur', 'ami', 'voir', 'jour', 'passer', 'quil', 'rend', 'visite', 'nouveau', 'occupation', 'partager']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **📌 6 : Vectorisation des textes**\n",
        " Transformer les tokens en vecteurs numériques utilisables pour entraîner un modèle d'IA."
      ],
      "metadata": {
        "id": "oZ-hj3Ki7pkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Convertir les tokens en texte\n",
        "df[\"text_clean\"] = df[\"tokens\"].apply(lambda tokens: \" \".join(tokens))\n",
        "\n",
        "# Initialiser le vectoriseur TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # On limite à 5000 features\n",
        "\n",
        "# Appliquer TF-IDF\n",
        "tqdm.pandas(desc=\"🔢 Application du TF-IDF\")\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(df[\"text_clean\"].progress_apply(str))\n",
        "\n",
        "# Vérifier la taille de la matrice\n",
        "print(\"✅ Matrice TF-IDF créée avec succès !\")\n",
        "print(f\"📏 Dimensions : {tfidf_matrix.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azT3OulI7qFI",
        "outputId": "f5b278d9-971e-453f-fc28-5cb9828eae67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🔢 Application du TF-IDF: 100%|██████████| 71213/71213 [00:00<00:00, 662585.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Matrice TF-IDF créée avec succès !\n",
            "📏 Dimensions : (71213, 5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pourquoi utiliser TF-IDF ?**\n",
        "\n",
        "✔ Pondère les mots en fonction de leur importance dans le corpus.\n",
        "\n",
        "✔ Utile pour les modèles classiques de NLP (SVM, Naïve Bayes, etc.).\n",
        "\n",
        "✔ Réduit l’impact des mots trop fréquents"
      ],
      "metadata": {
        "id": "vedH4jSg8C-0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **📌 7 : Sauvegarde des résultats**\n",
        "\n",
        "✔ Enregistrer le dataset pré-traité en .csv."
      ],
      "metadata": {
        "id": "8plAJQuaBNMm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Enregistrer le dataset avec les tokens\n",
        "df.to_csv(\"livres_pretraite.csv\", index=False)\n",
        "\n",
        "print(\"✅ Dataset pré-traité sauvegardé en CSV avec succès !\")\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "# Télécharger le dataset pré-traité\n",
        "files.download(\"livres_pretraite.csv\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "nWwwGvk8Bd0t",
        "outputId": "847821a2-ff8d-4b5d-fbfa-61e39374f279"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Modèle Word2Vec sauvegardé avec succès !\n",
            "✅ Dataset pré-traité sauvegardé en CSV avec succès !\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a29b5bc3-5b64-4494-ac12-c79a97808cda\", \"word2vec_books.model\", 68556257)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b2f7c298-85c8-471d-952d-3d0965bf620d\", \"livres_pretraite.csv\", 199586035)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}